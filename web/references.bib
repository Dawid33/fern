
@article{pai_t_systematic_2020,
	title = {A {Systematic} {Literature} {Review} of {Lexical} {Analyzer} {Implementation} {Techniques} in {Compiler} {Design}},
	issn = {2581-7000},
	url = {https://srinivaspublication.com/wp-content/uploads/2021/01/20.-Compiler-Design_Fullpaper.pdf},
	doi = {10.47992/IJAEML.2581.7000.0087},
	abstract = {The term “lexical” in lexical analysis process of the compilation is derived from the word “lexeme”, which is the basic conceptual unit of the linguistic morphological study. In computer science, lexical analysis, also referred to as lexing, scanning or tokenization, is the process of transforming the string of characters in source program to a stream of tokens, where the token is a string with a designated and identified meaning. It is the first phase of a two-step compilation processing model known as the analysis stage of compilation process used by compiler to understand the input source program. The objective is to convert character streams into words and recognize its token type. The generated stream of tokens is then used by the parser to determine the syntax of the source program. A program in compilation phase that performs a lexical analysis process is termed as lexical analyzer, lexer, scanner or tokenizer. Lexical analyzer is used in various computer science applications, such as word processing,information retrieval systems, pattern recognition systems and language-processing systems. However, the scope of our review study is related to language processing. Various tools are used for automatic generation of tokens and are more suitable for sequential execution of the process. Recent advances in multi-core architecture systems have led to the need to re-engineer the compilation process to integrate the multi-core architecture. By parallelization in the recognition of tokens in multiple cores, multi cores can be used optimally, thus reducing compilation time. To attain parallelism in tokenizationon multi-core machines, the lexical analyzer phase of compilation needs to be restructured to accommodate the multi-core architecture and by exploiting the language constructs which can run parallel and the concept of processor affinity. This paper provides a systematic analysis of literature to discuss emerging approaches and issues related to lexical analyzer implementation and the adoption of improved methodologies. This has been achieved by reviewing 30 published articles on the implementation of lexical analyzers. The results of this review indicate various techniques, latest developments, and current approaches for implementing auto generated scanners and hand-crafted scanners. Based on the findings, we draw on the efficacy of lexical analyzer implementation techniques from the results discussed in the selected review studies and the paper provides future research challenges and needs to explore the previously under-researched areas for scanner implementation processes.},
	language = {en},
	urldate = {2023-09-18},
	journal = {International Journal of Applied Engineering and Management Letters},
	author = {Pai T, Vaikunta and Jayanthila Devi, A. and Aithal, P. S.},
	month = dec,
	year = {2020},
	pages = {285--301},
	file = {Full Text:/home/dawids/Zotero/storage/N4L7YSNQ/Pai T et al. - 2020 - A Systematic Literature Review of Lexical Analyzer.pdf:application/pdf},
}

@article{barve_improved_2015,
	title = {Improved {Parallel} {Lexical} {Analysis} {Using} {OpenMP} on {Multi}-core {Machines}},
	volume = {49},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050915007553},
	doi = {10.1016/j.procs.2015.04.246},
	language = {en},
	urldate = {2023-09-18},
	journal = {Procedia Computer Science},
	author = {Barve, Amit and Joshi, Brijendra Kumar},
	year = {2015},
	pages = {211--219},
	file = {Barve and Joshi - 2015 - Improved Parallel Lexical Analysis Using OpenMP on.pdf:/home/dawids/Zotero/storage/AKLUGFY5/Barve and Joshi - 2015 - Improved Parallel Lexical Analysis Using OpenMP on.pdf:application/pdf},
}

@inproceedings{barve_parallel_2012,
	address = {Indore, Madhay Pradesh, India},
	title = {A parallel lexical analyzer for multi-core machines},
	isbn = {978-1-4673-2177-8 978-1-4673-2174-7 978-1-4673-2175-4 978-1-4673-2176-1},
	url = {http://ieeexplore.ieee.org/document/6349505/},
	doi = {10.1109/CONSEG.2012.6349505},
	urldate = {2023-09-18},
	booktitle = {2012 {CSI} {Sixth} {International} {Conference} on {Software} {Engineering} ({CONSEG})},
	publisher = {IEEE},
	author = {Barve, Amit and Joshi, Brijendra Kumar},
	month = sep,
	year = {2012},
	pages = {1--3},
}

@article{barve_parallel_2014,
	title = {Parallel {Lexical} {Analysis} of {Multiple} {Files} on {Multi}-{Core} {Machines}},
	volume = {96},
	issn = {09758887},
	url = {http://research.ijcaonline.org/volume96/number16/pxc3896879.pdf},
	doi = {10.5120/16879-6879},
	number = {16},
	urldate = {2023-09-18},
	journal = {International Journal of Computer Applications},
	author = {Barve, Amit and Kumar Joshi, Brijendra},
	month = jun,
	year = {2014},
	pages = {22--24},
	file = {Full Text:/home/dawids/Zotero/storage/X7ZW35FY/Barve and Kumar Joshi - 2014 - Parallel Lexical Analysis of Multiple Files on Mul.pdf:application/pdf;pxc3896879.pdf:/home/dawids/Zotero/storage/FZHD2DKG/pxc3896879.pdf:application/pdf},
}

@article{jena_design_2018,
	title = {Design and {Development} of a {Parallel} {Lexical} {Analyzer} for {C} {Language}:},
	volume = {8},
	issn = {2155-6393, 2155-6407},
	shorttitle = {Design and {Development} of a {Parallel} {Lexical} {Analyzer} for {C} {Language}},
	url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJKBO.2018010105},
	doi = {10.4018/IJKBO.2018010105},
	abstract = {Future of computing is rapidly moving towards massively multi-core architecture because of its power and cost advantages. Almost everywhere Multi-core processors are being used now-a-days and number of cores per chip is also relatively increasing. To exploit full potential offered by multi-core architecture, the system software like compilers should be designed for parallelized execution. In the past, various significant works have been made to change the design of traditional compiler to take advantages of the future multi-core platform. This paper focuses on adapting parallelism in the lexical analysis phase of the compilation process. The main objective of our proposal is to do the lexical analysis i.e., finding the tokens in an input stream in parallel. We use the parallel constructs available in OpenMP to achieve parallelism in the lexical analysis process for multi-core machines. The experimental result of our proposal shows a significant performance improvement in the parallel lexical analysis phase as compared to sequential version in terms of time of execution.},
	language = {en},
	number = {1},
	urldate = {2023-09-18},
	journal = {International Journal of Knowledge-Based Organizations},
	author = {Jena, Swagat Kumar and Das, Satyabrata and Sahoo, Satya Prakash},
	month = jan,
	year = {2018},
	pages = {68--82},
}

@phdthesis{komathukattil_evaluating_nodate,
	title = {Evaluating {Speedup} in {Parallel} {Compilers}},
	language = {en},
	author = {Komathukattil, Deepa V},
	file = {Komathukattil - Evaluating Speedup in Parallel Compilers.pdf:/home/dawids/Zotero/storage/QBQKIBMX/Komathukattil - Evaluating Speedup in Parallel Compilers.pdf:application/pdf},
}

@article{baer_model_1977,
	title = {Model, {Design}, and {Evaluation} of a {Compiler} for a {Parallel} {Processing} {Environment}},
	volume = {SE-3},
	issn = {0098-5589},
	url = {http://ieeexplore.ieee.org/document/1702471/},
	doi = {10.1109/TSE.1977.231172},
	number = {6},
	urldate = {2023-09-18},
	journal = {IEEE Transactions on Software Engineering},
	author = {Baer, J.-L. and Ellis, C.S.},
	month = nov,
	year = {1977},
	pages = {394--405},
	file = {Baer and Ellis - 1977 - Model, Design, and Evaluation of a Compiler for a .pdf:/home/dawids/Zotero/storage/YLB3I7UP/Baer and Ellis - 1977 - Model, Design, and Evaluation of a Compiler for a .pdf:application/pdf},
}

@book{waite_compiler_1984,
	address = {New York, NY},
	title = {Compiler {Construction}},
	isbn = {978-1-4612-9731-4 978-1-4612-5192-7},
	url = {http://link.springer.com/10.1007/978-1-4612-5192-7},
	urldate = {2023-09-18},
	publisher = {Springer New York},
	author = {Waite, William M. and Goos, Gerhard},
	year = {1984},
	doi = {10.1007/978-1-4612-5192-7},
	file = {Waite and Goos - 1984 - Compiler Construction.pdf:/home/dawids/Zotero/storage/2KEUCG8W/Waite and Goos - 1984 - Compiler Construction.pdf:application/pdf},
}

@inproceedings{voetter_compilation_2022,
	address = {Turin Italy},
	title = {Compilation on the {GPU}?: a feasibility study},
	isbn = {978-1-4503-9338-6},
	shorttitle = {Compilation on the {GPU}?},
	url = {https://dl.acm.org/doi/10.1145/3528416.3530249},
	doi = {10.1145/3528416.3530249},
	language = {en},
	urldate = {2023-09-18},
	booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Computing} {Frontiers}},
	publisher = {ACM},
	author = {Voetter, Robin F. and Huijben, Marcel and Rietveld, Kristian F. D.},
	month = may,
	year = {2022},
	pages = {230--236},
	file = {Compilation On The GPU A Feasibility Study.pdf:/home/dawids/Zotero/storage/57ZQN97L/Compilation On The GPU A Feasibility Study.pdf:application/pdf;Full Text:/home/dawids/Zotero/storage/ICHKHZJ9/Voetter et al. - 2022 - Compilation on the GPU a feasibility study.pdf:application/pdf},
}

@inproceedings{li_associative_2023,
	address = {Singapore Singapore},
	title = {Associative {Operator} {Precedence} {Parsing}: {A} {Method} {To} {Increase} {Data} {Parsing} {Parallelism}},
	isbn = {978-1-4503-9805-3},
	shorttitle = {Associative {Operator} {Precedence} {Parsing}},
	url = {https://dl.acm.org/doi/10.1145/3578178.3578233},
	doi = {10.1145/3578178.3578233},
	language = {en},
	urldate = {2023-09-18},
	booktitle = {Proceedings of the {International} {Conference} on {High} {Performance} {Computing} in {Asia}-{Pacific} {Region}},
	publisher = {ACM},
	author = {Li, Le and Taura, Kenjiro},
	month = feb,
	year = {2023},
	pages = {75--87},
	file = {Full Text:/home/dawids/Zotero/storage/KBWPQCS8/Li and Taura - 2023 - Associative Operator Precedence Parsing A Method .pdf:application/pdf},
}

@article{barenghi_parallel_2015,
	title = {Parallel parsing made practical},
	volume = {112},
	issn = {01676423},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167642315002610},
	doi = {10.1016/j.scico.2015.09.002},
	language = {en},
	urldate = {2023-09-18},
	journal = {Science of Computer Programming},
	author = {Barenghi, Alessandro and Crespi Reghizzi, Stefano and Mandrioli, Dino and Panella, Federica and Pradella, Matteo},
	month = nov,
	year = {2015},
	pages = {195--226},
	file = {Parallel parsing made practical.pdf:/home/dawids/Zotero/storage/SCSEINHB/Parallel parsing made practical.pdf:application/pdf},
}

@article{droste_weighted_2022,
	title = {Weighted operator precedence languages},
	volume = {282},
	issn = {0890-5401},
	url = {https://www.sciencedirect.com/science/article/pii/S0890540120301462},
	doi = {https://doi.org/10.1016/j.ic.2020.104658},
	abstract = {In the last years renewed investigation of operator precedence languages (OPL) led to discover important properties thereof: OPL are closed with respect to all major operations, are characterized, besides by the original grammar family, in terms of an automata family (OPA) and an MSO logic; furthermore they significantly generalize the well-known visibly pushdown languages (VPL). A different area of research investigates quantitative evaluations of formal languages by adding weights to strings. In this paper, we lay the foundation to marry these two research fields. We introduce weighted operator precedence automata and show how they are both strict extensions of OPA and weighted visibly pushdown automata. We prove a Nivat-like result which shows that quantitative OPL can be described by unweighted OPA and very particular weighted OPA. In a Büchi-like theorem, we show that weighted OPA are expressively equivalent to a weighted MSO-logic for OPL.},
	journal = {Information and Computation},
	author = {Droste, Manfred and Dück, Stefan and Mandrioli, Dino and Pradella, Matteo},
	year = {2022},
	keywords = {Input-driven languages, Operator precedence languages, Quantitative automata, Quantitative logic, Visibly pushdown languages},
	pages = {104658},
	annote = {Special issue on 9th International Workshop Weighted Automata: Theory and Applications (WATA 2018)},
	file = {Droste et al. - 2022 - Weighted operator precedence languages.pdf:/home/dawids/Zotero/storage/JMC2WMCI/Droste et al. - 2022 - Weighted operator precedence languages.pdf:application/pdf},
}

@article{reghizzi_toward_2017,
	title = {Toward a theory of input-driven locally parsable languages},
	volume = {658},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397516301165},
	doi = {https://doi.org/10.1016/j.tcs.2016.05.003},
	abstract = {If a context-free language enjoys the local parsability property then, no matter how the source string is segmented, each segment can be parsed independently, and an efficient parallel parsing algorithm becomes possible. The new class of locally chain parsable languages (LCPLs), included in the deterministic context-free language family, is here defined by means of the chain-driven automaton and characterized by decidable properties of grammar derivations. Such automaton decides whether to reduce or not a substring in a way purely driven by the terminal characters, thus extending the well-known concept of input-driven (ID) alias visibly pushdown machines. The LCPL family extends and improves the practically relevant Floyd's operator-precedence (OP) languages which are known to strictly include the ID languages, and for which a parallel-parser generator exists.},
	journal = {Theoretical Computer Science},
	author = {Reghizzi, Stefano Crespi and Lonati, Violetta and Mandrioli, Dino and Pradella, Matteo},
	year = {2017},
	keywords = {Input-driven languages, Operator precedence languages, Visibly pushdown languages, Parallel parsing},
	pages = {105--121},
	annote = {Formal Languages and Automata: Models, Methods and Application In honour of the 70th birthday of Antonio Restivo},
	file = {Reghizzi et al. - 2017 - Toward a theory of input-driven locally parsable l.pdf:/home/dawids/Zotero/storage/24BQVZLL/Reghizzi et al. - 2017 - Toward a theory of input-driven locally parsable l.pdf:application/pdf},
}

@inproceedings{sinya_simultaneous_2013,
	address = {Lyon, France},
	title = {Simultaneous {Finite} {Automata}: {An} {Efficient} {Data}-{Parallel} {Model} for {Regular} {Expression} {Matching}},
	isbn = {978-0-7695-5117-3},
	shorttitle = {Simultaneous {Finite} {Automata}},
	url = {http://ieeexplore.ieee.org/document/6687355/},
	doi = {10.1109/ICPP.2013.31},
	abstract = {Automata play important roles in wide area of computing and the growth of multicores calls for their efﬁcient parallel implementation. Though it is known in theory that we can perform the computation of a ﬁnite automaton in parallel by simulating transitions, its implementation has a large overhead due to the simulation. In this paper we propose a new automaton called simultaneous ﬁnite automaton (SFA) for efﬁcient parallel computation of an automaton. The key idea is to extend an automaton so that it involves the simulation of transitions. Since an SFA itself has a good property of parallelism, we can develop easily a parallel implementation without overheads. We have implemented a regular expression matcher based on SFA, and it has achieved over 10-times speedups on an environment with dual hexa-core CPUs in a typical case.},
	language = {en},
	urldate = {2023-10-24},
	booktitle = {2013 42nd {International} {Conference} on {Parallel} {Processing}},
	publisher = {IEEE},
	author = {Sinya, Ryoma and Matsuzaki, Kiminori and Sassa, Masataka},
	month = oct,
	year = {2013},
	pages = {220--229},
	file = {Sinya et al. - 2013 - Simultaneous Finite Automata An Efficient Data-Pa.pdf:/home/dawids/Zotero/storage/L4USJFV3/Sinya et al. - 2013 - Simultaneous Finite Automata An Efficient Data-Pa.pdf:application/pdf},
}

@book{grune_parsing_2008,
	address = {New York, NY},
	series = {Monographs in {Computer} {Science}},
	title = {Parsing {Techniques}},
	isbn = {978-0-387-20248-8 978-0-387-68954-8},
	url = {http://link.springer.com/10.1007/978-0-387-68954-8},
	urldate = {2023-10-24},
	publisher = {Springer New York},
	author = {Grune, Dick and Jacobs, Ceriel J. H.},
	year = {2008},
	doi = {10.1007/978-0-387-68954-8},
}

@inproceedings{li_plex_2021,
	address = {Portland, OR, USA},
	title = {Plex: {Scaling} {Parallel} {Lexing} with {Backtrack}-{Free} {Prescanning}},
	isbn = {978-1-66544-066-0},
	shorttitle = {Plex},
	url = {https://ieeexplore.ieee.org/document/9460518/},
	doi = {10.1109/IPDPS49936.2021.00079},
	abstract = {Lexical analysis, which converts input text into a list of tokens, plays an important role in many applications, including compilation and data extraction from texts. To recognize token patterns, a lexer incorporates a sequential computation model — automaton as its basic building component. As such, it is considered diﬃcult to parallelize due to the inherent data dependency. Much work has been done to accelerate lexical analysis through parallel techniques. Unfortunately, existing attempts mainly rely on language-speciﬁc remedies for input segmentation, which makes it not only tricky for language extension, but also challenging for automatic lexer generation.},
	language = {en},
	urldate = {2023-10-24},
	booktitle = {2021 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	publisher = {IEEE},
	author = {Li, Le and Sato, Shigeyuki and Liu, Qiheng and Taura, Kenjiro},
	month = may,
	year = {2021},
	pages = {693--702},
	file = {Li et al. - 2021 - Plex Scaling Parallel Lexing with Backtrack-Free .pdf:/home/dawids/Zotero/storage/Z4P4S45W/Li et al. - 2021 - Plex Scaling Parallel Lexing with Backtrack-Free .pdf:application/pdf},
}

@article{skrzypczak_parallel_nodate,
	title = {Parallel parsing of context-free grammars},
	language = {en},
	author = {Skrzypczak, Piotr},
	file = {Skrzypczak - Parallel parsing of context-free grammars.pdf:/home/dawids/Zotero/storage/LQK49237/Skrzypczak - Parallel parsing of context-free grammars.pdf:application/pdf},
}

@phdthesis{robin_voetter_parallel_2021,
	type = {Thesis {Master} {Computer} {Science}},
	title = {Parallel {Lexing}, {Parsing} and {Semantic} {Analysis} on the {GPU}},
	url = {https://theses.liacs.nl/2053},
	abstract = {In this thesis, we describe the design and implementation of the front end of a compiler of which all major stages can be executed on a Graphical Pro- cessing Unit (GPU). The lexical-, syntactic- and semantic analysis stages are implemented in terms of data-parallel primitives provided by the Futhark pro- gramming language. A series of experiments show that our implementation scales well for large source input, but suffers from the overhead of scheduling and distribution of work for smaller input.},
	school = {LIACS, Leiden University},
	author = {{Robin Voetter}},
	year = {2021},
	file = {Robin Voetter - 2021 - Parallel Lexing, Parsing and Semantic Analysis on .pdf:/home/dawids/Zotero/storage/G67LTZIQ/Robin Voetter - 2021 - Parallel Lexing, Parsing and Semantic Analysis on .pdf:application/pdf},
}

@techreport{mark_thierry_vandevoorde_parallel_1988,
	title = {Parallel {Compilation} on a {Tightly} {Coupled} {Multiprocessor}},
	url = {https://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-26.pdf},
	urldate = {2023-10-24},
	author = {{Mark Thierry Vandevoorde}},
	month = mar,
	year = {1988},
	file = {Parallel Compilation on a Tightly Coupled Multiprocessor.pdf:/home/dawids/Zotero/storage/QPSQNKIF/Parallel Compilation on a Tightly Coupled Multiprocessor.pdf:application/pdf},
}

@inproceedings{gross_parallel_1989,
	address = {New York, NY, USA},
	series = {{PLDI} '89},
	title = {Parallel {Compilation} for a {Parallel} {Machine}},
	isbn = {0-89791-306-X},
	url = {https://doi.org/10.1145/73141.74826},
	doi = {10.1145/73141.74826},
	abstract = {An application for a parallel computer with multiple, independent processors often includes different programs (functions) for the individual processors; compilation of such functions can proceed independently. We implemented a compiler that exploits this parallelism by partitioning the input program for parallel translation. The host system for the parallel compiler is an Ethernet-based network of workstations, and different functions of the application program are compiled in parallel on different workstations. For typical programs in our environment, we observe a speedup ranging from 3 to 6 using not more than 9 processors. The paper includes detailed measurements for this parallel compiler; we report the system overhead, implementation overhead, as well as the speedup obtained when compared with sequential compilation.},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1989 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {Association for Computing Machinery},
	author = {Gross, T. and Sobel, A. and Zolg, M.},
	year = {1989},
	note = {event-place: Portland, Oregon, USA},
	pages = {91--100},
	file = {Gross et al. - 1989 - Parallel Compilation for a Parallel Machine.pdf:/home/dawids/Zotero/storage/3IBSAFGI/Gross et al. - 1989 - Parallel Compilation for a Parallel Machine.pdf:application/pdf},
}

@phdthesis{huijben_parallel_2021,
	type = {Thesis {Master} {Computer} {Science}},
	title = {Parallel {Code} {Generation} on the {GPU}},
	url = {https://theses.liacs.nl/2053},
	abstract = {Traditional compilers are single-threaded programs running on CPUs that perform a sequential set of stages in order to transform the source code of a program into a machine representation. Recently, GPUs have become in- creasingly powerful and programmable and could be used to speed up modern compilers. By using only GPU primitives which can be efficiently executed on modern GPUs, we have designed and implemented a compiler that can be run on the GPU. This thesis describes the backend of the Pareas compiler, which transforms the abstract syntax tree generated by the frontend into machine code for the RISC-V architecture using a novel set of compilation stages. The performance of our implementation was characterized under various types of inputs. The experimental results show that the implementation scales well for wide abstract syntax trees reminiscent of real-world source files. However, for long functions the register allocation stage imposes a significant overhead},
	school = {LIACS, Leiden University},
	author = {Huijben, Marcel},
	year = {2021},
	file = {Huijben - 2021 - Parallel Code Generation on the GPU.pdf:/home/dawids/Zotero/storage/T628RS3G/Huijben - 2021 - Parallel Code Generation on the GPU.pdf:application/pdf},
}

@article{reghizzi_higher-order_2017,
	title = {Higher-{Order} {Operator} {Precedence} {Languages}},
	volume = {252},
	url = {https://doi.org/10.4204%2Feptcs.252.11},
	doi = {10.4204/eptcs.252.11},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Reghizzi, Stefano Crespi and Pradella, Matteo},
	month = aug,
	year = {2017},
	note = {Publisher: Open Publishing Association},
	pages = {86--100},
	file = {Reghizzi and Pradella - 2017 - Higher-Order Operator Precedence Languages.pdf:/home/dawids/Zotero/storage/S5TVYZB8/Reghizzi and Pradella - 2017 - Higher-Order Operator Precedence Languages.pdf:application/pdf},
}

@inproceedings{scarpazza_high-performance_2009,
	address = {New York, NY, USA},
	series = {{ICS} '09},
	title = {High-{Performance} {Regular} {Expression} {Scanning} on the {Cell}/{B}.{E}. {Processor}},
	isbn = {978-1-60558-498-0},
	url = {https://doi.org/10.1145/1542275.1542284},
	doi = {10.1145/1542275.1542284},
	abstract = {Matching regular expressions (regexps) is a very common work-load. For example, tokenization, which consists of recognizing words or keywords in a character stream, appears in every search engine indexer. Tokenization also consumes 30\% or more of most XML processors' execution time and represents the first stage of any programming language compiler.Despite the multi-core revolution, regexp scanner generators like flex haven't changed much in 20 years, and they do not exploit the power of recent multi-core architectures (e.g., multiple threads and wide SIMD units). This is unfortunate, especially given the pervasive importance of search engines and the fast growth of our digital universe. Indexing such data volumes demands precisely the processing power that multi-cores are designed to offer.We present an algorithm and a set of techniques for using multi-core features such as multiple threads and SIMD instructions to perform parallel regexp-based tokenization.As a proof of concept, we present a family of optimized kernels that implement our algorithm, providing the features of flex on the Cell/B.E. processor at top performance. Our kernels achieve almost-ideal resource utilization (99.2\% of the clock cycles are non-NOP issues). They deliver a peak throughput of 14.30 Gbps per Cell chip, and 9.76 Gbps on Wikipedia input: a remarkable performance, comparable to dedicated hardware solutions. Also, our kernels show speedups of 57-81× over flex on the Cell.Our approach is valuable because it is easily portable to other SIMD-enabled processors, and there is a general trend toward more and wider SIMD instructions in architecture design.},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Supercomputing}},
	publisher = {Association for Computing Machinery},
	author = {Scarpazza, Daniele Paolo and Russell, Gregory F.},
	year = {2009},
	note = {event-place: Yorktown Heights, NY, USA},
	keywords = {cell processor, multi-core, regular expressions},
	pages = {14--25},
	file = {Scarpazza and Russell - 2009 - High-Performance Regular Expression Scanning on th.pdf:/home/dawids/Zotero/storage/3Z8FS2KB/Scarpazza and Russell - 2009 - High-Performance Regular Expression Scanning on th.pdf:application/pdf},
}

@inproceedings{mytkowicz_data-parallel_2014,
	address = {New York, NY, USA},
	series = {{ASPLOS} '14},
	title = {Data-{Parallel} {Finite}-{State} {Machines}},
	isbn = {978-1-4503-2305-5},
	url = {https://doi.org/10.1145/2541940.2541988},
	doi = {10.1145/2541940.2541988},
	abstract = {A finite-state machine (FSM) is an important abstraction for solving several problems, including regular-expression matching, tokenizing text, and Huffman decoding. FSM computations typically involve data-dependent iterations with unpredictable memory-access patterns making them difficult to parallelize. This paper describes a parallel algorithm for FSMs that breaks dependences across iterations by efficiently enumerating transitions from all possible states on each input symbol. This allows the algorithm to utilize various sources of data parallelism available on modern hardware, including vector instructions and multiple processors/cores. For instance, on benchmarks from three FSM applications: regular expressions, Huffman decoding, and HTML tokenization, the parallel algorithm achieves up to a 3x speedup over optimized sequential baselines on a single core, and linear speedups up to 21x on 8 cores.},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mytkowicz, Todd and Musuvathi, Madanlal and Schulte, Wolfram},
	year = {2014},
	note = {event-place: Salt Lake City, Utah, USA},
	keywords = {data parallel, finite state machine, regular expression},
	pages = {529--542},
	file = {Mytkowicz et al. - 2014 - Data-Parallel Finite-State Machines.pdf:/home/dawids/Zotero/storage/Z3MLY5ZR/Mytkowicz et al. - 2014 - Data-Parallel Finite-State Machines.pdf:application/pdf},
}

@article{hillis_data_1986,
	title = {Data {Parallel} {Algorithms}},
	volume = {29},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/7902.7903},
	doi = {10.1145/7902.7903},
	abstract = {Parallel computers with tens of thousands of processors are typically programmed in a data parallel style, as opposed to the control parallel style used in multiprocessing. The success of data parallel algorithms—even on problems that at first glance seem inherently serial—suggests that this style of programming has much wider applicability than was previously thought.},
	number = {12},
	journal = {Commun. ACM},
	author = {Hillis, W. Daniel and Steele, Guy L.},
	month = dec,
	year = {1986},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {1170--1183},
	file = {Hillis and Steele - 1986 - Data Parallel Algorithms.pdf:/home/dawids/Zotero/storage/WQV2UQJC/Hillis and Steele - 1986 - Data Parallel Algorithms.pdf:application/pdf},
}

@article{reghizzi_beyond_2020,
	title = {Beyond operator-precedence grammars and languages},
	volume = {113},
	issn = {0022-0000},
	url = {https://www.sciencedirect.com/science/article/pii/S002200001830182X},
	doi = {https://doi.org/10.1016/j.jcss.2020.04.006},
	abstract = {Operator Precedence Languages (OPL) are deterministic context-free and have desirable properties. OPL are parallely parsable, and, when structurally compatible, are closed under Boolean operations, concatenation and star; they include the Input Driven languages. OPL use three relations between two terminal symbols, to assign syntax structure to words. We extend such relations to k-tuples of consecutive symbols, in agreement with strictly locally testable regular languages. For each k, the new corresponding class of Higher-order Operator Precedence languages properly includes the OPL and enjoy many of their properties. OPL are a strict hierarchy based on k, which contains maximal languages.},
	journal = {Journal of Computer and System Sciences},
	author = {Reghizzi, Stefano Crespi and Pradella, Matteo},
	year = {2020},
	keywords = {Input-driven languages, Operator precedence languages, Visibly pushdown languages, Boolean closure, Deterministic context-free languages, Grammar inference, Local parsability, Locally testable languages, Syntactic tags},
	pages = {18--41},
	file = {Reghizzi and Pradella - 2020 - Beyond operator-precedence grammars and languages.pdf:/home/dawids/Zotero/storage/4MJYE3NM/Reghizzi and Pradella - 2020 - Beyond operator-precedence grammars and languages.pdf:application/pdf},
}

@article{lin_accelerating_2013,
	title = {Accelerating {Pattern} {Matching} {Using} a {Novel} {Parallel} {Algorithm} on {GPUs}},
	volume = {62},
	doi = {10.1109/TC.2012.254},
	number = {10},
	journal = {IEEE Transactions on Computers},
	author = {Lin, Cheng-Hung and Liu, Chen-Hsiung and Chien, Lung-Sheng and Chang, Shih-Chieh},
	year = {2013},
	pages = {1906--1916},
	file = {Lin et al. - 2013 - Accelerating Pattern Matching Using a Novel Parall.pdf:/home/dawids/Zotero/storage/TYNZGQGS/Lin et al. - 2013 - Accelerating Pattern Matching Using a Novel Parall.pdf:application/pdf},
}

@article{fisher_parallel_2004,
	title = {Parallel {Processing}: {A} {Smart} {Compiler} and a {Dumb} {Machine}},
	volume = {39},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/989393.989408},
	doi = {10.1145/989393.989408},
	abstract = {Multiprocessors and vector machines, the only successful parallel architectures, have coarse-grained parallelism that is hard for compilers to take advantage of. We've developed a new fine-grained parallel architecture and a compiler that together offer order-of-magnitude speedups for ordinary scientific code.},
	number = {4},
	journal = {SIGPLAN Not.},
	author = {Fisher, Joseph A. and Ellis, John R. and Ruttenberg, John C. and Nicolau, Alexandru},
	month = apr,
	year = {2004},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {112--124},
}

@inproceedings{roesch_snort_1999,
	address = {USA},
	series = {{LISA} '99},
	title = {Snort - {Lightweight} {Intrusion} {Detection} for {Networks}},
	abstract = {Network intrusion detection systems (NIDS) are an important part of any network security architecture. They provide a layer of defense which monitors network traffic for predefined suspicious activity or patterns, and alert system administrators when potential hostile traffic is detected. Commercial NIDS have many differences, but Information Systems departments must face the commonalities that they share such as significant system footprint, complex deployment and high monetary cost. Snort was designed to address these issues.},
	booktitle = {Proceedings of the 13th {USENIX} {Conference} on {System} {Administration}},
	publisher = {USENIX Association},
	author = {Roesch, Martin},
	year = {1999},
	note = {event-place: Seattle, Washington},
	pages = {229--238},
}

@inproceedings{wang_hyperscan_2019,
	address = {Boston, MA},
	title = {Hyperscan: {A} {Fast} {Multi}-pattern {Regex} {Matcher} for {Modern} {CPUs}},
	isbn = {978-1-931971-49-2},
	url = {https://www.usenix.org/conference/nsdi19/presentation/wang-xiang},
	booktitle = {16th {USENIX} {Symposium} on {Networked} {Systems} {Design} and {Implementation} ({NSDI} 19)},
	publisher = {USENIX Association},
	author = {Wang, Xiang and Hong, Yang and Chang, Harry and Park, KyoungSoo and Langdale, Geoff and Hu, Jiayu and Zhu, Heqing},
	month = feb,
	year = {2019},
	pages = {631--648},
}

@article{howard_parallel_1996,
	title = {Parallel lossless image compression using {Huffman} and arithmetic coding},
	volume = {59},
	issn = {0020-0190},
	url = {https://www.sciencedirect.com/science/article/pii/0020019096000907},
	doi = {https://doi.org/10.1016/0020-0190(96)00090-7},
	abstract = {We show that high-resolution images can be encoded and decoded efficiently in parallel. We present an algorithm based on the hierarchical MLP method, used either with Huffman coding or with a new variant of arithmetic coding called quasi-arithmetic coding. The coding step can be parallelized, even though the codes for different pixels are of different lengths; parallelization of the prediction and error modeling components is straightforward.},
	number = {2},
	journal = {Information Processing Letters},
	author = {Howard, Paul G. and Vitter, Jeffrey Scott},
	year = {1996},
	keywords = {Arithmetic coding, Data compression, Huffman coding, Parallel algorithms},
	pages = {65--73},
}

@article{hall_compiler_2009,
	title = {Compiler {Research}: {The} next 50 {Years}},
	volume = {52},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/1461928.1461946},
	doi = {10.1145/1461928.1461946},
	abstract = {Research and education in compiler technology is more important than ever.},
	number = {2},
	journal = {Commun. ACM},
	author = {Hall, Mary and Padua, David and Pingali, Keshav},
	month = feb,
	year = {2009},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {60--67},
}

@article{ward-foxton_rocm_2023,
	title = {{ROCm} {Is} {AMD}’s {No}. 1 {Priority}, {Exec} {Says}},
	url = {https://www.eetimes.com/rocm-is-amds-no-1-priority-exec-says/},
	abstract = {AMD’s Vamsi Boppana admits software is a journey, but the open-source community can "help bridge the gap."},
	urldate = {2023-10-26},
	journal = {EE Times},
	author = {Ward-Foxton, Sally},
	month = sep,
	year = {2023},
	file = {Snapshot:/home/dawids/Zotero/storage/D84V4MNQ/rocm-is-amds-no-1-priority-exec-says.html:text/html},
}
